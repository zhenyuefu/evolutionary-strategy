{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2023-03-10 10:36:06 GMT\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import logger as gymlogger\n",
    "# from gym.wrappers import Monitor # deprecated 2023 - https://stackoverflow.com/questions/71520568/importerror-cannot-import-name-monitor-from-gym-wrappers\n",
    "from gymnasium.wrappers.record_video import RecordVideo\n",
    "gymlogger.set_level(40) #error only\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\"\\n\",date.today(), datetime.now().strftime(\"%H:%M:%S\"),\"GMT\") # timestamp is greenwich time\n",
    "print(\"OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2023-03-10 10:36:06 GMT\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A simple neural network object\n",
    "# source: https://github.com/AsmaBRZ/Evolutionary-algorithms/blob/master/fixed_structure_nn_numpy.py\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## Suppress TF info messages\n",
    "\n",
    "import os\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def gen_simplemlp(n_in, n_out, n_hidden_layers=2, n_neurons_per_hidden=5):\n",
    "    n_neurons = [n_neurons_per_hidden]*n_hidden_layers if np.isscalar(n_neurons_per_hidden) else n_neurons_per_hidden\n",
    "    i = Input(shape=(n_in,))\n",
    "    x = i\n",
    "    for n in n_neurons:\n",
    "        x = Dense(n, activation='sigmoid')(x)\n",
    "    o = Dense(n_out, activation='tanh')(x)\n",
    "    m = Model(inputs=i, outputs=o)\n",
    "    return m\n",
    "\n",
    "\n",
    "class SimpleNeuralControllerNumpy():\n",
    "    def __init__(self, n_in, n_out, n_hidden_layers=2, n_neurons_per_hidden=5, params=None):\n",
    "        self.dim_in = n_in\n",
    "        self.dim_out = n_out\n",
    "        # if params is provided, we look for the number of hidden layers and neuron per layer into that parameter (a dicttionary)\n",
    "        if (not params==None):\n",
    "            if (\"n_hidden_layers\" in params.keys()):\n",
    "                n_hidden_layers=params[\"n_hidden_layers\"]\n",
    "            if (\"n_neurons_per_hidden\" in params.keys()):\n",
    "                n_neurons_per_hidden=params[\"n_neurons_per_hidden\"]\n",
    "        self.n_per_hidden = n_neurons_per_hidden\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.weights = None\n",
    "        self.n_weights = None\n",
    "        self.init_random_params()\n",
    "        self.out = np.zeros(n_out)\n",
    "        #print(\"Creating a simple mlp with %d inputs, %d outputs, %d hidden layers and %d neurons per layer\"%(n_in, n_out,n_hidden_layers, n_neurons_per_hidden))\n",
    "\n",
    "\n",
    "    def init_random_params(self):\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            self.weights = [np.random.random((self.dim_in,self.n_per_hidden))] # In -> first hidden\n",
    "            self.bias = [np.random.random(self.n_per_hidden)] # In -> first hidden\n",
    "            for i in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                self.weights.append(np.random.random((self.n_per_hidden,self.n_per_hidden)))\n",
    "                self.bias.append(np.random.random(self.n_per_hidden))\n",
    "            self.weights.append(np.random.random((self.n_per_hidden,self.dim_out))) # -> last hidden -> out\n",
    "            self.bias.append(np.random.random(self.dim_out))\n",
    "        else:\n",
    "            self.weights = [np.random.random((self.dim_in,self.dim_out))] # Single-layer perceptron\n",
    "            self.bias = [np.random.random(self.dim_out)]\n",
    "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
    "\n",
    "    def get_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns all network parameters as a single array\n",
    "        \"\"\"\n",
    "        flat_weights = np.hstack([arr.flatten() for arr in (self.weights+self.bias)])\n",
    "        return flat_weights\n",
    "\n",
    "    def set_parameters(self, flat_parameters):\n",
    "        \"\"\"\n",
    "        Set all network parameters from a single array\n",
    "        \"\"\"\n",
    "        i = 0 # index\n",
    "        to_set = []\n",
    "        self.weights = list()\n",
    "        self.bias = list()\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            # In -> first hidden\n",
    "            w0 = np.array(flat_parameters[i:(i+self.dim_in*self.n_per_hidden)])\n",
    "            self.weights.append(w0.reshape(self.dim_in,self.n_per_hidden))\n",
    "            i += self.dim_in*self.n_per_hidden\n",
    "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                w = np.array(flat_parameters[i:(i+self.n_per_hidden*self.n_per_hidden)])\n",
    "                self.weights.append(w.reshape((self.n_per_hidden,self.n_per_hidden)))\n",
    "                i += self.n_per_hidden*self.n_per_hidden\n",
    "            # -> last hidden -> out\n",
    "            wN = np.array(flat_parameters[i:(i+self.n_per_hidden*self.dim_out)])\n",
    "            self.weights.append(wN.reshape((self.n_per_hidden,self.dim_out)))\n",
    "            i += self.n_per_hidden*self.dim_out\n",
    "            # Samefor bias now\n",
    "            # In -> first hidden\n",
    "            b0 = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
    "            self.bias.append(b0)\n",
    "            i += self.n_per_hidden\n",
    "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                b = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
    "                self.bias.append(b)\n",
    "                i += self.n_per_hidden\n",
    "            # -> last hidden -> out\n",
    "            bN = np.array(flat_parameters[i:(i+self.dim_out)])\n",
    "            self.bias.append(bN)\n",
    "            i += self.dim_out\n",
    "        else:\n",
    "            n_w = self.dim_in*self.dim_out\n",
    "            w = np.array(flat_parameters[:n_w])\n",
    "            self.weights = [w.reshape((self.dim_in,self.dim_out))]\n",
    "            self.bias = [np.array(flat_parameters[n_w:])]\n",
    "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
    "\n",
    "    def predict(self,x):\n",
    "        \"\"\"\n",
    "        Propagate\n",
    "        \"\"\"\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            #Input\n",
    "            a = np.matmul(x,self.weights[0]) + self.bias[0]\n",
    "            y = sigmoid(a)\n",
    "            # hidden -> hidden\n",
    "            for i in range(1,self.n_hidden_layers-1):\n",
    "                a = np.matmul(y, self.weights[i]) + self.bias[i]\n",
    "                y = sigmoid(a)\n",
    "            # Out\n",
    "            a = np.matmul(y, self.weights[-1]) + self.bias[-1]\n",
    "            out = tanh(a)\n",
    "            return out\n",
    "        else: # Simple monolayer perceptron\n",
    "            return tanh(np.matmul(x,self.weights[0]) + self.bias[0])\n",
    "\n",
    "    def __call__(self,x):\n",
    "        \"\"\"Calling the controller calls predict\"\"\"\n",
    "        return self.predict(x)\n",
    "\n",
    "print(\"\\n\",date.today(), datetime.now().strftime(\"%H:%M:%S\"),\"GMT\") # timestamp is greenwich time\n",
    "print(\"OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: [-0.01718654  0.00780112  0.02278244 -0.02092541] <class 'numpy.ndarray'> (4,)\n",
      "obs: [-0.03872223  0.01280517  0.01505941  0.04271357] <class 'numpy.ndarray'> (4,)\n",
      "obs: [-0.02709858 -0.0141231   0.04538532  0.04090934] <class 'numpy.ndarray'> (4,)\n",
      "obs: [-0.01625654  0.00461658 -0.01663846  0.00144274] <class 'numpy.ndarray'> (4,)\n",
      "obs: [-0.02753758  0.02384411  0.02081367  0.04301481] <class 'numpy.ndarray'> (4,)\n",
      "obs: [-0.01335328  0.02161715 -0.01359328 -0.02682093] <class 'numpy.ndarray'> (4,)\n",
      "obs: [ 0.0095457  -0.01175741  0.02942055 -0.04101792] <class 'numpy.ndarray'> (4,)\n",
      "obs: [ 0.01807426  0.02142726  0.04410785 -0.0292872 ] <class 'numpy.ndarray'> (4,)\n",
      "obs: [-0.0453118  -0.01616802  0.01359317  0.0102906 ] <class 'numpy.ndarray'> (4,)\n",
      "obs: [ 0.04835679  0.04047988 -0.02707644  0.03287368] <class 'numpy.ndarray'> (4,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make('CartPole-v1', render_mode='human')\n",
    "# env = wrap_env( gym.make('CartPole-v1') ) # colab-specific # needs py-game (import in earlier cell)\n",
    "\n",
    "observation, info = env.reset()\n",
    "\n",
    "#for _ in range(1000):\n",
    "#while True:\n",
    "maxEvaluations = 10\n",
    "evaluation = 0\n",
    "while evaluation < maxEvaluations:\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "      evaluation = evaluation + 1\n",
    "      observation, info = env.reset()\n",
    "      print (\"obs:\",observation,type(observation),observation.shape)\n",
    "      #show_video(False) # colab-specific\n",
    "\n",
    "env.close()\n",
    "\n",
    "# show_video() # colab-specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question B-1\n",
    "\n",
    "En partant de l'exemple de la documentation et du code fourni pour le réseau de neurones dans la première cellule ci-dessous, faites une expérience pour optimiser les paramètres d'un réseau de neurones contrôlant un pendule inversé (environnement 'CartPole-v1') avec CMA-ES. Imposez une limite à 500 pas de temps au-delà de laquelle l'expérience est considérée comme réussie.\n",
    "\n",
    "使用文档中的例子和为下面第一个单元格中的神经网络提供的代码，执行一个实验来优化用CMA-ES控制倒立摆的神经网络的参数（CartPole-v1环境）。设置500个时间步数的限制，超过这个时间步数就认为实验成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN parameters: [-0.21863377 -0.25891941  0.27295175  0.828277    0.50751095  0.80650617\n",
      "  0.52375932 -0.32483662 -0.68591724  0.6684494  -0.2342329   0.06805185\n",
      " -0.18531291  0.0604336  -0.29983903 -0.89446921  0.44398634 -0.43973455\n",
      " -0.068092    0.08385179  0.61662309  0.51756617 -0.3742084   0.0668632\n",
      " -0.34095977  0.62863114  0.08673652  0.52568422 -0.22516899 -0.51382779\n",
      "  0.58550383 -0.41254502 -0.0758776  -0.38717772  0.57303667  0.89517319\n",
      " -0.78107305 -0.28601248  0.46629837  0.67344502  0.15252293 -0.84970598\n",
      "  0.91824432 -0.46018826  0.18838473 -0.60418321 -0.3733826  -0.65015385\n",
      " -0.01326887  0.7676656  -0.42479103  0.52414    -0.93094318  0.73436807\n",
      " -0.17486381  0.78960326  0.52941792 -0.17165798 -0.88015825  0.57305472\n",
      "  0.40667645]\n",
      "Input values: [-0.03760372  0.00724161 -0.03663132  0.01225319]\n",
      "Output values: [0.08865271]\n"
     ]
    }
   ],
   "source": [
    "# Exemple de création d'un réseau de neurones multi-couches (\"multi-layered perceptron\")\n",
    "\n",
    "nbInputs = 4\n",
    "nbOutputs = 1\n",
    "nbHiddenLayers = 2\n",
    "nbNeuronsPerLayer = 5\n",
    "\n",
    "nn=SimpleNeuralControllerNumpy(nbInputs,nbOutputs,nbHiddenLayers,nbNeuronsPerLayer)\n",
    "\n",
    "# NN parameters\n",
    "\n",
    "theta = nn.get_parameters() # get default parameters\n",
    "for i in range(len(theta)):\n",
    "  theta[i] = random.random()*2.0-1.0 # set our own parameter values\n",
    "nn.set_parameters(theta)\n",
    "print (\"NN parameters:\",theta)\n",
    "\n",
    "# running NN\n",
    "\n",
    "observation = np.array( [ -0.03760372,0.00724161,-0.03663132,0.01225319 ], np.float64 )\n",
    "\n",
    "print (\"Input values:\", observation)\n",
    "\n",
    "outputValues = nn.predict(observation)\n",
    "\n",
    "print (\"Output values:\", outputValues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8_w,16)-aCMA-ES (mu_w=4.8,w_1=32%) in dimension 67 (seed=573436, Fri Mar 10 10:45:54 2023)\n",
      "best fitness: -500.0\n",
      "mean fitness: -61.8125\n",
      "best NN parameters: [ 1.59475564e+00  5.01047694e-01 -5.44594455e-01 -8.13165205e-01\n",
      "  6.05432100e-01 -1.82124551e+00  3.36233642e-01  1.04225215e+00\n",
      "  6.02841885e-01  5.59786900e-01  1.13420781e+00  2.15721695e+00\n",
      "  5.92929208e-01 -7.46770380e-01  2.23375332e+00 -7.55442791e-01\n",
      "  1.03071673e+00  3.84907672e-01  5.85019835e-01  1.32164473e+00\n",
      "  6.73201193e-01  6.80194115e-01 -3.08729286e-01  4.87985930e-02\n",
      "  1.97301620e+00  6.72388710e-01  6.74057786e-01  2.32499642e+00\n",
      "  9.94895985e-01 -1.20435512e+00 -1.47086287e+00  1.32965317e-01\n",
      "  9.84186371e-01  5.08847503e-01 -1.40786473e-01  9.28702301e-01\n",
      "  5.08347095e-01  1.38661532e+00  4.04127942e-01  2.26145875e+00\n",
      " -3.75085574e-01 -3.87366610e-01 -4.60073786e-01 -7.57253525e-01\n",
      "  4.97909886e-01 -4.68723733e-01  6.86423531e-01  3.16643223e-02\n",
      "  1.20710254e+00 -1.01283317e-01  3.32714456e-01 -6.75936191e-01\n",
      "  1.02790950e+00  1.52339903e+00  8.16306298e-01  6.47893817e-01\n",
      "  3.16223116e-01  7.13764079e-01  7.30610668e-01  5.06357316e-01\n",
      " -1.05415522e+00  6.73283751e-01 -1.19837957e+00  7.34463553e-01\n",
      "  1.01037370e+00  3.70417819e-02  1.12909966e-04]\n"
     ]
    }
   ],
   "source": [
    "from cma import CMAEvolutionStrategy\n",
    "\n",
    "def evaluate_nn(nn, theta):\n",
    "    observation, info = env.reset()\n",
    "    nn.set_parameters(theta)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    num_steps = 0\n",
    "    while not done and total_reward < 500:\n",
    "        output = nn.predict(observation)[0]\n",
    "        action = 0 if output < 0 else 1\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        num_steps += 1\n",
    "    env.close()\n",
    "    return -total_reward\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "observation, info = env.reset()\n",
    "nbInputs = env.observation_space.shape[0]\n",
    "nbOutputs = env.action_space.n\n",
    "nbHiddenLayers = 2\n",
    "nbNeuronsPerLayer = 5\n",
    "nn=SimpleNeuralControllerNumpy(nbInputs,nbOutputs,nbHiddenLayers,nbNeuronsPerLayer)\n",
    "initial_params = nn.get_parameters()\n",
    "# optimize the parameters using CMA-ES\n",
    "es = CMAEvolutionStrategy(initial_params, 0.5)\n",
    "while not es.stop() and es.result.fbest > -500:\n",
    "    solutions = es.ask()\n",
    "    fitness_list = [evaluate_nn(nn,s) for s in solutions ]\n",
    "    es.tell(solutions, fitness_list)\n",
    "print('best fitness:', es.best.f)\n",
    "print('mean fitness:', np.mean(fitness_list))\n",
    "print('best NN parameters:', es.best.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
